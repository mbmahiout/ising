{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "path2cpp_pkg = \"/Users/mariusmahiout/Documents/repos/ising_core/build\"\n",
    "sys.path.append(path2cpp_pkg)\n",
    "import ising\n",
    "\n",
    "import os\n",
    "os.chdir(\"/Users/mariusmahiout/Documents/repos/ising_core/python\")\n",
    "\n",
    "import src.misc_plotting as plotting\n",
    "import src.utils as utils\n",
    "import src.model_eval as eval\n",
    "import src.isingfitter as fitter\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_units = 30\n",
    "num_sims = 15000\n",
    "num_burn = 1000\n",
    "lr = 0.01\n",
    "max_steps = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation took 0.04 seconds.\n"
     ]
    }
   ],
   "source": [
    "##############\n",
    "# SIMULATION #\n",
    "##############\n",
    "\n",
    "# setting up model\n",
    "beta = 1.3\n",
    "h = np.random.uniform(-.3 * beta, .3 * beta, num_units)\n",
    "J = np.random.normal(0,  beta / np.sqrt(num_units), (num_units, num_units))\n",
    "for i in range(num_units):\n",
    "    J[i, i] = 0\n",
    "    for j in range(i+1, num_units):\n",
    "        J[j, i] = J[i, j]\n",
    "\n",
    "true_model = ising.EqModel(num_units, J, h)\n",
    "\n",
    "# simulating\n",
    "t0 = time.time()\n",
    "\n",
    "true_sim = true_model.simulate(num_sims, num_burn)\n",
    "\n",
    "t1 = time.time()\n",
    "dt = t1 - t0\n",
    "print(\"Simulation took {:.2f} seconds.\".format(dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference took 9.86 seconds.\n"
     ]
    }
   ],
   "source": [
    "#############\n",
    "# INFERENCE #\n",
    "#############\n",
    "\n",
    "# setting up model\n",
    "h_init = np.random.uniform(-1.5, 1.5, num_units)\n",
    "J_init = np.random.normal(0,  1,  (num_units, num_units))\n",
    "J_init = (J_init.T + J_init) * np.sqrt(2) / 2\n",
    "np.fill_diagonal(J_init, 0)\n",
    "\n",
    "ml_model = ising.EqModel(num_units, J_init, h_init)\n",
    "\n",
    "ml_fitter = fitter.EqFitter(ml_model)\n",
    "ml_fitter.TAP(true_sim)\n",
    "\n",
    "# inference\n",
    "t0 = time.time()\n",
    "\n",
    "ml_fitter.maximize_likelihood(\n",
    "    sample=true_sim, \n",
    "    max_steps=max_steps, \n",
    "    learning_rate=lr, \n",
    "    num_sims=num_sims, \n",
    "    num_burn=num_burn,\n",
    ")\n",
    "\n",
    "t1 = time.time()\n",
    "dt = t1 - t0\n",
    "print(\"Inference took {:.2f} seconds.\".format(dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_model = ising.EqModel(num_units, J_init, h_init)\n",
    "tap_model = ising.EqModel(num_units, J_init, h_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_fitter = fitter.EqFitter(nmf_model)\n",
    "nmf_fitter.naive_mean_field(true_sim)\n",
    "\n",
    "tap_fitter = fitter.EqFitter(tap_model)\n",
    "tap_fitter.TAP(true_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "# SIMULATION #\n",
    "##############\n",
    "\n",
    "ml_sim = ml_model.simulate(num_sims, num_burn)\n",
    "nmf_sim = nmf_model.simulate(num_sims, num_burn)\n",
    "tap_sim = tap_model.simulate(num_sims, num_burn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata(\n",
    "    num_units,\n",
    "    is_empirical_analysis,\n",
    "    eq_inv_methods=[],\n",
    "    neq_inv_methods=[],\n",
    "    **kwargs\n",
    "):\n",
    "    metadata = {}\n",
    "    metadata[\"num_units\"] = num_units\n",
    "\n",
    "    if is_empirical_analysis:\n",
    "        bin_width = kwargs['bin_width']\n",
    "        num_bins = kwargs['num_bins']\n",
    "        metadata['bin_width'] = bin_width\n",
    "    else:\n",
    "        num_sims = kwargs['num_sims']\n",
    "        num_burn = kwargs.get('num_burn', 1000)\n",
    "        true_fields = kwargs['true_fields']\n",
    "        true_couplings = kwargs['true_couplings']\n",
    "        metadata[\"true_model\"] = {\n",
    "            'true_fields' : true_fields,\n",
    "            'true_couplings' : true_couplings,\n",
    "            'num_sims' : num_sims,\n",
    "            'num_burn' : num_burn,\n",
    "        }\n",
    "\n",
    "    if (eq_inv_methods != []) or (neq_inv_methods != []):\n",
    "        metadata[\"inverse_methods\"] = {\n",
    "            'EQ' : eq_inv_methods,\n",
    "            'NEQ' : neq_inv_methods,\n",
    "        }\n",
    "        if ('ML' in eq_inv_methods) or ('ML' in neq_inv_methods):\n",
    "            # each can be dict if multiple ML models with different hyperparams\n",
    "            num_steps = kwargs['num_steps']\n",
    "            learning_rate = kwargs['learning_rate']\n",
    "            is_converged = kwargs['is_converged']\n",
    "            metadata['maximum_likelihood'] = {\n",
    "                'num_steps' : num_steps,\n",
    "                'learning_rate' : learning_rate,\n",
    "                'is_converged' : is_converged,\n",
    "            }\n",
    "        if ('ML' in eq_inv_methods):\n",
    "            num_sims_ml = kwargs['num_sims_ml']\n",
    "            num_burn_ml = kwargs.get('num_burn_ml', 1000)\n",
    "            metadata['maximum_likelihood']['num_sims'] = num_sims_ml\n",
    "            metadata['maximum_likelihood']['num_burn'] = num_burn_ml\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51f6b240855143428627019fd502c04a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FigureWidget({\n",
       "    'data': [{'legendgroup': 'ML',\n",
       "              'marker': {'color': 'blue', 'siâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = [\"ML\", \"nMF\", \"TAP\"]\n",
    "metadata = get_metadata(\n",
    "    num_units=num_units,\n",
    "    is_empirical_analysis=False,\n",
    "    eq_inv_methods=labels,\n",
    "    num_sims=num_sims,\n",
    "    true_fields=\"uniform(-.3 * beta, .3 * beta); beta=1.3\",\n",
    "    true_couplings=\"normal(0,  beta / sqrt(num_units)); symmetric, beta=1.3\",\n",
    "    num_steps=max_steps,\n",
    "    learning_rate=lr,\n",
    "    is_converged=None,\n",
    "    num_sims_ml=num_sims,\n",
    "    num_burn_ml=num_burn,\n",
    ")\n",
    "\n",
    "\n",
    "def get_analysis_path(analysis_name, num_units, bin_width):\n",
    "    analysis_path = '../analyses/'\n",
    "    dir_name = f'n{num_units}b{bin_width}{analysis_name}'\n",
    "    analysis_path += f'./{dir_name}/'\n",
    "    return analysis_path\n",
    "\n",
    "\n",
    "analysis_name = \"test\"\n",
    "bin_width = 0\n",
    "analysis_path = get_analysis_path(analysis_name, num_units, bin_width)\n",
    "\n",
    "layout_spec = {\n",
    "    (\"fields\", \"scatter\"): (1, 1),\n",
    "    (\"means\", \"scatter\"): (1, 2),\n",
    "    (\"couplings\", \"scatter\"): (2, 1),\n",
    "    (\"pcorrs\", \"scatter\"): (2, 2),\n",
    "}\n",
    "\n",
    "ising_eval = eval.IsingEval(\n",
    "    analysis_path=analysis_path, \n",
    "    metadata=metadata, \n",
    "    true_model=true_model, \n",
    "    est_models=[ml_model, nmf_model, tap_model],\n",
    "    true_sample=true_sim,\n",
    "    est_samples=[ml_sim, nmf_sim, tap_sim], \n",
    "    labels=labels,\n",
    "    layout_spec=layout_spec\n",
    ")\n",
    "ising_eval.generate_plots()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting parameters history\n",
    "Could return a struct consisting of \n",
    "1. A vector with all the fields\n",
    "2. A vector with all the couplings\n",
    "3. Optionally, a vector with all the LLHs\n",
    "\n",
    "Note: a tripple would not be sufficient, if we want to be able to chose whether or not to return the LLHs! (I believe a struct will be our best bet for this)\n",
    "\n",
    "If we do this, we change the function from void setMaxLikelihoodParams() to\n",
    "struct maximumLikelihood(). In other words, this will be a function that does two things:\n",
    "1. Modifies the model parameters in-place\n",
    "2. returns the history via the struct"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps\n",
    "1. We need deeper insights into the workings of the gradient ascent implementations. For this purpose, I'd like to store the same quantities I did for the python implementation using the C++ code:\n",
    "    - Parameter history (fields and couplings)\n",
    "    - log likelihoods (will only be feasible for smaller models)\n",
    "2. Try to figure out why the pseudolikelihood method is less performant than the exact LLH maximization procedure...\n",
    "3. Implement the NEQ stuff\n",
    "4. Testing the sampler (this should be much quicker now!)\n",
    "5. Reproduce some of the figures from Nguyen et al. (and/or from one of Yasser's papers)\n",
    "\n",
    "\n",
    "## C++ code\n",
    "1. Functionality for storing parameter history (in exact_infer)\n",
    "2. Functionality for computing LLHs (in models? Have a think about this)\n",
    "3. NEQ stuff\n",
    "\n",
    "## Python code\n",
    "1. Adapt IsingFitter to have attributes for parameter history etc.\n",
    "2. Include code for plotting history and all that\n",
    "3. NEQ stuff\n",
    "\n",
    "\n",
    "When all of the above is finished, we're almost done, the remainder incldues:\n",
    "- Including the code for dealing with neural recordings (I think this should be easy, and will happen in python)\n",
    "- Investigating the observables for the neural recordings\n",
    "- Fitting some good models to the neural recordings.\n",
    "    - Here, I'm thinking I'll use a combined approach, somehting like TAP -> PL -> ML (EQ), and TAP -> ML (NEQ)\n",
    "    - We can also do a few runs of fitting with all the methods seperately, but this should not be the main focus\n",
    "    - Ideally, we can extract some insight into the neural data from the models, once they've been fitted\n",
    "\n",
    "Note: Consider paying for compute? Need to get up to speed on how to use this, but I don't think this should be that hard...\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Once project is finalized\n",
    "- Make public on GitHub (exclude the data)\n",
    "- Get in touch with Yasser (Also, congratulate him on his new position and ask how he's doing)\n",
    "- Add it to projects on website\n",
    "- Perhaps make a blog post discussing your decision to revize the project\n",
    "    - Got hurried at the end, and although I recieved top marks, was not happy with the final product (figures, code, etc.).\n",
    "    - At the time, I was still a novice programmer and a novice in ML, and so a lot of the efforts were spent on learning the basics of ML and software development\n",
    "    - Conclusion of the above: despite recieving an A, there was ample room for improvement.\n",
    "    - Wanted to learn C++ (with high performance computing and robotics applications in mind), and so thought revizing a previous software project would be a good way to get my feet wet. In particular, my masters project involved some heavy computations, and so was a good candidate for this\n",
    "    - Note: at this point, should also discuss some of the performance gains you saw\n",
    "- Consider doing a mini-project related to RBMs, with an associated blog post(s) introducing RBMS, and one discussing the project\n",
    "\n",
    "Note: could also add the IRL project to the website (don't have to make a big deal out of this --> should only take an afternoon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ising_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e4b2a17a10a08aa999978f2e8c22cb8993313908924239efe5123bc7400ca19a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
