{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "path2cpp_pkg = \"/Users/mariusmahiout/Documents/repos/ising_core/build\"\n",
    "sys.path.append(path2cpp_pkg)\n",
    "import ising\n",
    "\n",
    "import os\n",
    "os.chdir(\"/Users/mariusmahiout/Documents/repos/ising_core/python/src\")\n",
    "import utils as utils\n",
    "import model_eval as eval\n",
    "import isingfitter as fitter\n",
    "import misc_plotting as plotting\n",
    "\n",
    "os.chdir(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "import plotly\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "plotly.offline.init_notebook_mode()\n",
    "display(HTML(\n",
    "    '<script type=\"text/javascript\" async src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_SVG\"></script>'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_units = 50\n",
    "num_sims = 15_000\n",
    "num_burn = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "# SIMULATION #\n",
    "##############\n",
    "\n",
    "# setting up model\n",
    "beta = 1.3\n",
    "h = np.random.uniform(-.3 * beta, .3 * beta, num_units)\n",
    "J = np.random.normal(0,  beta / np.sqrt(num_units), (num_units, num_units))\n",
    "for i in range(num_units):\n",
    "    J[i, i] = 0\n",
    "    for j in range(i+1, num_units):\n",
    "        J[j, i] = J[i, j]\n",
    "\n",
    "true_model = ising.EqModel(J, h)\n",
    "\n",
    "# simulating\n",
    "true_sim = true_model.simulate(num_sims, num_burn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_sample, test_sample = utils.get_train_test_samples(true_sim)\n",
    "train_sample = true_sim\n",
    "test_sample = true_sim"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient ascent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sims = 50_000\n",
    "num_burn = 2500\n",
    "lr = 0.1\n",
    "win_size = 10\n",
    "tol_ml = 1e-4\n",
    "tol_pl = 1e-6\n",
    "max_steps = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "# LIKELIHOOD #\n",
    "##############\n",
    "\n",
    "# setting up model\n",
    "h_init = np.random.uniform(-1.5, 1.5, num_units)\n",
    "J_init = np.random.normal(0,  1,  (num_units, num_units))\n",
    "J_init = (J_init.T + J_init) * np.sqrt(2) / 2\n",
    "np.fill_diagonal(J_init, 0)\n",
    "\n",
    "ml_model = ising.EqModel(J_init, h_init)\n",
    "\n",
    "ml_fitter = fitter.EqFitter(ml_model)\n",
    "ml_fitter.TAP(train_sample)\n",
    "\n",
    "# inference\n",
    "use_llh = False\n",
    "\n",
    "ml_fitter.maximize_likelihood(\n",
    "    sample=train_sample,\n",
    "    max_steps=1000, \n",
    "    learning_rate=0.1,\n",
    "    win_size = win_size,\n",
    "    tolerance= tol_ml, \n",
    "    num_sims=num_sims, \n",
    "    num_burn=num_burn,\n",
    "    calc_llh=use_llh\n",
    ")\n",
    "\n",
    "# ml_fitter.maximize_likelihood(\n",
    "#     sample=train_sample,\n",
    "#     max_steps=1000, \n",
    "#     learning_rate=0.05,\n",
    "#     win_size = win_size,\n",
    "#     tolerance= tol_ml, \n",
    "#     num_sims=num_sims, \n",
    "#     num_burn=num_burn,\n",
    "#     calc_llh=use_llh\n",
    "# )\n",
    "\n",
    "# ml_fitter.maximize_likelihood(\n",
    "#     sample=train_sample,\n",
    "#     max_steps=1500, \n",
    "#     learning_rate=0.01,\n",
    "#     win_size = win_size,\n",
    "#     tolerance= tol_ml, \n",
    "#     num_sims=num_sims, \n",
    "#     num_burn=num_burn,\n",
    "#     calc_llh=use_llh\n",
    "# )\n",
    "\n",
    "# ml_fitter.maximize_likelihood(\n",
    "#     sample=train_sample,\n",
    "#     max_steps=1500, \n",
    "#     learning_rate=0.005,\n",
    "#     win_size = win_size,\n",
    "#     tolerance= tol_ml, \n",
    "#     num_sims=num_sims, \n",
    "#     num_burn=num_burn,\n",
    "#     calc_llh=use_llh\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.convergence_plot(ml_fitter, plot_llh=use_llh, path=f\"./analyses/eq_convergence/ml{num_units}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# PSEUDO-LIKELIHOOD #\n",
    "#####################\n",
    "\n",
    "# setting up model\n",
    "h_init = np.random.uniform(-1.5, 1.5, num_units)\n",
    "J_init = np.random.normal(0,  1,  (num_units, num_units))\n",
    "J_init = (J_init.T + J_init) * np.sqrt(2) / 2\n",
    "np.fill_diagonal(J_init, 0)\n",
    "\n",
    "pl_model = ising.EqModel(J_init, h_init)\n",
    "pl_fitter = fitter.EqFitter(pl_model)\n",
    "pl_fitter.TAP(train_sample)\n",
    "\n",
    "# inference\n",
    "pl_fitter.maximize_likelihood(\n",
    "    sample=train_sample, \n",
    "    max_steps=1000, \n",
    "    learning_rate=0.1,\n",
    "    win_size = win_size,\n",
    "    tolerance= tol_pl, \n",
    "    num_sims=0, \n",
    "    num_burn=0,\n",
    ")\n",
    "\n",
    "# pl_fitter.maximize_likelihood(\n",
    "#     sample=train_sample, \n",
    "#     max_steps=1000, \n",
    "#     learning_rate=0.05,\n",
    "#     win_size = win_size,\n",
    "#     tolerance= tol_pl, \n",
    "#     num_sims=0, \n",
    "#     num_burn=0,\n",
    "# )\n",
    "\n",
    "# pl_fitter.maximize_likelihood(\n",
    "#     sample=train_sample, \n",
    "#     max_steps=1500, \n",
    "#     learning_rate=0.01,\n",
    "#     win_size = win_size,\n",
    "#     tolerance= tol_pl, \n",
    "#     num_sims=0, \n",
    "#     num_burn=0,\n",
    "# )\n",
    "\n",
    "# pl_fitter.maximize_likelihood(\n",
    "#     sample=train_sample, \n",
    "#     max_steps=1500, \n",
    "#     learning_rate=0.005,\n",
    "#     win_size = win_size,\n",
    "#     tolerance= tol_pl, \n",
    "#     num_sims=0, \n",
    "#     num_burn=0,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.convergence_plot(pl_fitter, plot_llh=use_llh, path=f\"./analyses/eq_convergence/pl{num_units}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_model = ising.EqModel(J_init, h_init)\n",
    "nmf_fitter = fitter.EqFitter(nmf_model)\n",
    "nmf_fitter.naive_mean_field(train_sample)\n",
    "\n",
    "tap_model = ising.EqModel(J_init, h_init)\n",
    "tap_fitter = fitter.EqFitter(tap_model)\n",
    "tap_fitter.TAP(train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_sim = ml_model.simulate(num_sims, num_burn)\n",
    "pl_sim = pl_model.simulate(num_sims, num_burn)\n",
    "nmf_sim = nmf_model.simulate(num_sims, num_burn)\n",
    "tap_sim = tap_model.simulate(num_sims, num_burn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "labels = [\"nMF\", \"TAP\", \"PLLH\", \"ML\"]\n",
    "metadata = utils.get_metadata(\n",
    "    num_units=num_units,\n",
    "    is_empirical_analysis=False,\n",
    "    eq_inv_methods=labels,\n",
    "    num_sims=num_sims,\n",
    "    true_fields=\"uniform(-.3 * beta, .3 * beta); beta=1.3\",\n",
    "    true_couplings=\"normal(0,  beta / sqrt(num_units)); symmetric, beta=1.3\",\n",
    "    num_steps=max_steps,\n",
    "    learning_rate=lr,\n",
    "    is_converged=None,\n",
    "    num_sims_ml=num_sims,\n",
    "    num_burn_ml=num_burn,\n",
    ")\n",
    "\n",
    "\n",
    "analysis_name = \"eq_test\"\n",
    "bin_width = 0\n",
    "analysis_path = utils.get_analysis_path(analysis_name, num_units, bin_width)\n",
    "\n",
    "layout_spec = {\n",
    "    # (\"fields\", \"scatter\"): (1, 1),\n",
    "    # (\"means\", \"scatter\"): (1, 2),\n",
    "    # (\"couplings\", \"scatter\"): (2, 1),\n",
    "    # (\"pcorrs\", \"scatter\"): (2, 2),\n",
    "    (\"num-distr\", \"histogram\"): (1, 1),\n",
    "\n",
    "}\n",
    "\n",
    "ising_eval = eval.IsingEval(\n",
    "    analysis_path=analysis_path,\n",
    "    metadata=metadata,\n",
    "    true_model=true_model,\n",
    "    est_models=[nmf_model, tap_model, pl_model, ml_model],\n",
    "    true_sample=test_sample,\n",
    "    est_samples=[nmf_sim, tap_sim, pl_sim, ml_sim],\n",
    "    labels=labels,\n",
    "    layout_spec=layout_spec\n",
    ")\n",
    "ising_eval.generate_plots(is_pdf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coactivation_distribution(states: np.ndarray):\n",
    "    num_units, num_bins = states.shape\n",
    "    rel_freq = np.zeros(num_units + 1)\n",
    "    for bin in range(num_bins):\n",
    "        active_units = states[:, bin] == 1\n",
    "        num_active = int(np.count_nonzero(active_units))\n",
    "        rel_freq[num_active] += 1 / num_bins\n",
    "    return rel_freq\n",
    "\n",
    "\n",
    "coac_distr = get_coactivation_distribution(test_sample.getStates())\n",
    "nmf_coac_distr = get_coactivation_distribution(nmf_sim.getStates())\n",
    "tap_coac_distr = get_coactivation_distribution(tap_sim.getStates())\n",
    "\n",
    "plt.plot(coac_distr, color=\"grey\")\n",
    "plt.plot(nmf_coac_distr, color=\"orange\")\n",
    "plt.plot(tap_coac_distr, color=\"slateblue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ideas to investigate:\n",
    "\n",
    "- Relationship between closeness of parameters (est & true) and and closeness of observables (e.g., means and pcorrs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ising_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e4b2a17a10a08aa999978f2e8c22cb8993313908924239efe5123bc7400ca19a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
